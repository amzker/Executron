{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fce814",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-601147ae3e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mconfig_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"data\")\n",
    "config_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"config\")\n",
    "model_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"model\")\n",
    "\n",
    "mapping_filename = os.path.join(data_dir, \"mappings.csv\")\n",
    "classes_file = os.path.join(config_dir, \"classes.txt\")\n",
    "word_index_file = os.path.join(config_dir, \"word_to_index.json\")\n",
    "max_tokens_file = os.path.join(config_dir, \"max_input\")\n",
    "model_path = os.path.join(model_dir, \"model_dict.json\")\n",
    "\n",
    "def load_word_to_index(filename):\n",
    "    with open(filename, 'r') as json_file:\n",
    "        word_to_index = json.load(json_file)\n",
    "    return word_to_index\n",
    "\n",
    "def load_max_input_size(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        max_input_size = int(file.read())\n",
    "    return max_input_size\n",
    "\n",
    "def preprocess_data(raw_text, word_to_index, max_input_size):\n",
    "    input_tokens = [word_to_index.get(word, 0) for word in word_tokenize(raw_text.lower())]\n",
    "\n",
    "    # Pad or truncate input tokens to match the model's input size\n",
    "    input_tokens = input_tokens[:max_input_size] + [0] * (max_input_size - len(input_tokens))\n",
    "\n",
    "    return np.array([input_tokens])\n",
    "\n",
    "def make_predictions(input_tokens, model):\n",
    "    predicted_output = model.predict(input_tokens)\n",
    "    return np.round(predicted_output)\n",
    "\n",
    "def nmpredict(raw_text, word_to_index, model, max_input_size):\n",
    "    input_tokens = preprocess_data(raw_text, word_to_index, max_input_size)\n",
    "    predictions = make_predictions(input_tokens, model)\n",
    "    mappings = pd.read_csv(mapping_filename)\n",
    "    mapping_dict = mappings.set_index(\"mapping\")[\"commands\"].to_dict()\n",
    "    predicted_commands = [\",\".join([mapping_dict[pred] for pred in prediction if pred in mapping_dict]) for prediction in predictions]\n",
    "    return predicted_commands\n",
    "\n",
    "word_to_index = load_word_to_index(word_index_file)\n",
    "max_input_size = load_max_input_size(max_tokens_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8187992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POLY2:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "        self.c = None\n",
    "        self.degree = None\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.mse = []\n",
    "        self.betas = []\n",
    "        self.itr = []\n",
    "\n",
    "    def polyrise(self, X, degree, interactions=False):\n",
    "        newx = np.asarray(X)\n",
    "\n",
    "        if newx.ndim == 1:\n",
    "            newx = newx.reshape(-1, 1)\n",
    "        X_poly = newx.copy()\n",
    "\n",
    "        for i in range(2, degree + 1):\n",
    "            X_poly = np.append(X_poly, newx ** i, axis=1)\n",
    "\n",
    "        return X_poly\n",
    "\n",
    "    def normalize(self, X):\n",
    "        smallvalue = 1e-10\n",
    "\n",
    "        X = (X - self.mean) / (self.std + smallvalue)\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, y, lr=0.01, epochs=100, degree=1, interactions=False, alpha=0.01):\n",
    "        self.degree = degree\n",
    "\n",
    "        X_poly = self.polyrise(X, degree, interactions)\n",
    "        y = np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        n_samples, n_features = X_poly.shape\n",
    "        n_outputs = y.shape[1]\n",
    "        self.beta = np.zeros((n_features, n_outputs))\n",
    "        self.c = np.zeros(n_outputs)\n",
    "        self.mean = np.mean(X_poly, axis=0)\n",
    "        self.std = np.std(X_poly, axis=0)\n",
    "        X_norm = self.normalize(X_poly)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            self.itr.append(i)\n",
    "            pred = X_norm.dot(self.beta) + self.c\n",
    "            error = y - pred\n",
    "            self.betas.append(self.beta)\n",
    "\n",
    "            self.mse.append(np.mean(np.absolute(error)))\n",
    "\n",
    "            # ∂β = −2/n Σ X.T(y−βX) +  α∗sign(β)\n",
    "\n",
    "            db = -2 / len(X_norm) * X_norm.T.dot(error)\n",
    "            lasso = alpha * np.sign(self.beta)\n",
    "            db = db + lasso\n",
    "\n",
    "            dc = (-2) * np.mean(error, axis=0)\n",
    "            self.beta = self.beta - (lr * db)\n",
    "            self.c = self.c - (lr * dc)\n",
    "        print(\"LAST MSE: \", np.mean(np.absolute(self.mse[-1])))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.beta is None or self.c is None:\n",
    "            raise RuntimeError(\"Model has not been trained. Please call model.fit() before model.predict().\")\n",
    "        X_poly = self.polyrise(X, self.degree, interactions=False)  # Ensure interactions are disabled\n",
    "        X_norm = self.normalize(X_poly)\n",
    "        return X_norm.dot(self.beta) + self.c\n",
    "\n",
    "    def evaluate(self, X, y_actual):\n",
    "        if self.beta is None or self.c is None:\n",
    "            raise RuntimeError(\"Model has not been trained. Please call model.fit() before model.evaluate().\")\n",
    "\n",
    "        X = X.to_numpy()\n",
    "\n",
    "        X_poly = self.polyrise(X, self.degree, interactions=False)\n",
    "        X_norm = self.normalize(X_poly)\n",
    "\n",
    "        y_pred = X_norm.dot(self.beta) + self.c\n",
    "\n",
    "        y_actual = np.squeeze(y_actual)\n",
    "        y_pred = np.squeeze(y_pred)\n",
    "\n",
    "        correct_predictions = np.sum(np.round(y_pred) == y_actual)\n",
    "        incorrect_predictions = len(y_actual) - correct_predictions\n",
    "\n",
    "        accuracy = correct_predictions / len(y_actual)\n",
    "\n",
    "        # i can use pandas to make beautiful tablke but i dont have energy anymore\n",
    "        print(\"Total Samples:\", len(y_actual))\n",
    "        print(\"Correct Predictions:\") \n",
    "        print(correct_predictions)\n",
    "        print(\"Incorrect Predictions:\") \n",
    "        print(incorrect_predictions)\n",
    "        print(\"Accuracy:\")\n",
    "        print(accuracy)\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'beta': self.beta.tolist() if self.beta is not None else None,\n",
    "            'c': self.c.tolist() if self.c is not None else None,\n",
    "            'degree': self.degree,\n",
    "            'mean': self.mean.tolist() if self.mean is not None else None,\n",
    "            'std': self.std.tolist() if self.std is not None else None,\n",
    "            'mse': self.mse,\n",
    "            'betas': [beta.tolist() for beta in self.betas] if self.betas else None,\n",
    "            'itr': self.itr\n",
    "        }\n",
    "\n",
    "    def from_dict(self, model_dict):\n",
    "        self.beta = np.array(model_dict['beta']) if model_dict['beta'] is not None else None\n",
    "        self.c = np.array(model_dict['c']) if model_dict['c'] is not None else None\n",
    "        self.degree = model_dict['degree']\n",
    "        self.mean = np.array(model_dict['mean']) if model_dict['mean'] is not None else None\n",
    "        self.std = np.array(model_dict['std']) if model_dict['std'] is not None else None\n",
    "        self.mse = model_dict['mse']\n",
    "        self.betas = [np.array(beta) for beta in model_dict['betas']] if model_dict['betas'] else None\n",
    "        self.itr = model_dict['itr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fdff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path, 'r') as file:\n",
    "    loaded_model_dict = json.load(file)\n",
    "\n",
    "model = POLY2()\n",
    "model.from_dict(loaded_model_dict)\n",
    "print(\"MODEL CONFIGURAION LOADED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699afd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(input_sentence):\n",
    "    predictions = nmpredict(input_sentence,word_to_index, model, max_input_size)\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
